# Data Source Risk Review

## Purpose
Evaluate whether proposed data sources are **safe, trustworthy, and decision-appropriate**
*before* they are cleaned, transformed, or modeled.

This prompt is designed to surface:
- misleading signals
- hidden dependencies
- feedback loops
- temporal or organizational risks

---

## AI Role
Reviewer (skeptical, risk-oriented)

---

## Prompt
Act as a critical reviewer of proposed data sources for the following decision system:

**Decision being supported:**  
[INSERT DECISION]

**Candidate data sources:**  
[List each data source separately]

For **each** data source, answer:

1. **What signal does this source provide?**  
   - What behavior or outcome does it appear to represent?

2. **How could this signal be misleading?**  
   Consider:
   - proxy effects
   - confounding factors
   - missing context
   - changes in collection logic

3. **What timing risks exist?**  
   Consider:
   - label delay
   - backfilled data
   - post-decision contamination
   - misalignment with when decisions are made

4. **What feedback loops could occur?**  
   - Could actions taken by the system influence future values of this data?
   - Could the system end up reinforcing its own beliefs?

5. **Who controls this data — and why does that matter?**  
   - Is the source generated by users, internal processes, or downstream actions?
   - How could organizational incentives shape this data?

---

## Constraints
Do **NOT**:
- recommend cleaning or transformation steps
- suggest feature engineering
- assess predictive power
- recommend models or metrics

Focus only on **trust, risk, and decision alignment**.

---

## Output Expectation
The output should:
- identify risks, not solutions
- distinguish between *signal* and *artifact*
- highlight where caution or human review is required

Uncertainty is expected.
Clarity about risk is the goal.

---

## Human Review Checklist
Before proceeding to cleaning or feature design, confirm:

- [ ] Each data source’s signal is clearly understood
- [ ] Major timing and feedback risks are documented
- [ ] Ownership and incentive structures are acknowledged
- [ ] High-risk sources are explicitly flagged (not silently accepted)

---

## Guiding Principle

> **If a data source cannot be defended in words,  
it should not be trusted in code.**
